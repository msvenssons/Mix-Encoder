{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vime_train import encodertrain, MLPperf, encoderperf, mixencodertrain, combinedencodertrain\n",
    "from vime_utils import preloader, dia_preloader, aucplot, mask_generator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show tensorboard\n",
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir=MixEncoder_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "N0data = preloader(\"N0_data.csv\")\n",
    "print(N0data.labels.dtype)\n",
    "\n",
    "diadata = dia_preloader(\"diabetes_data.csv\")\n",
    "print(diadata.labels.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup seeds and sizes array\n",
    "seeds = [2127, 10291, 61691, 912811, 44444, 7562, 5678910, 192927, 58517, 5607] # can be one value or multiple depending on how many runs you want to analyze\n",
    "sizes = [0.1, 0.2625, 0.425, 0.5875, 0.75] # dia #[0.25, 0.375, 0.5, 0.625, 0.75] # N0\n",
    "\n",
    "# setup result array\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train MLP\n",
    "\n",
    "# variable size, seed, and L2\n",
    "MLP_steps = 4000\n",
    "MLP_batch_size = 200\n",
    "MLP_weight_decay = [0.063, 0.062, 0.061, 0.03, 0] #dia #[0.06, 0.058, 0.056, 0.054, 0.04] N0\n",
    "\n",
    "MLP_epochs = [int((MLP_steps*MLP_batch_size)/(x*800)) for x in sizes]\n",
    "MLP_results = []\n",
    "\n",
    "for k in range(len(sizes)):\n",
    "    MLP_sizeresults = []\n",
    "    for i in seeds:\n",
    "        MLP_seedresults, _ = MLPperf(diadata, kfold=False, epochs=MLP_epochs[k], lr=0.0001, seed=i, batch_size=MLP_batch_size, trainsize=sizes[k], weight_decay=MLP_weight_decay[k])\n",
    "        MLP_sizeresults.append(MLP_seedresults)\n",
    "    MLP_results.append(MLP_sizeresults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append to results\n",
    "results.append(MLP_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot results of different sizes and seeds (if used above)\n",
    "aucplot(results, sizes, title=\"MLP\", save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train encoder\n",
    "encodertrain(diadata, kfold=False, epochs=7000, lr=0.0001, alpha=3.0, p_m=0.2, batch_size=200, trainsize=0.9, valsize=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train mix encoder\n",
    "mixencodertrain(diadata, kfold=False, epochs=50000, lr=0.0001, folds=2, batch_size=200, trainsize=0.9, valsize=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train VIME encoder-MLP\n",
    "VIME_checkpoint = \"add your VIME checkpoint here\"\n",
    "\n",
    "# variable size and seed\n",
    "VIME_steps = 4000 # 12000\n",
    "VIME_batch_size = 200\n",
    "VIME_weight_decay = [0.05, 0.03, 0.02, 0.005, 0.005] #dia # [0.038, 0.028, 0.028, 0.026, 0.02] #N0\n",
    "VIME_epochs = [int((VIME_steps*VIME_batch_size)/(x*800)) for x in sizes]\n",
    "VIME_results = []\n",
    "\n",
    "for k in range(len(sizes)):\n",
    "    VIME_sizeresults = []\n",
    "    for i in seeds:\n",
    "        VIME_seedresults, _ = encoderperf(diadata, kfold=False, checkpoint=VIME_checkpoint, epochs=VIME_epochs[k], lr=0.0001, seed=i, batch_size=VIME_batch_size, trainsize=sizes[k], weight_decay=VIME_weight_decay[k], en_weight_decay=0.01, encoder_type=\"VIME\")\n",
    "        VIME_sizeresults.append(VIME_seedresults)\n",
    "    VIME_results.append(VIME_sizeresults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append to results\n",
    "results.append(VIME_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot results of different sizes and seeds (if used above)\n",
    "aucplot(results, sizes, title=\"VIME Encoder\", save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train Mix encoder-MLP\n",
    "MIX_checkpoint = \"add your MIX checkpoint here\"\n",
    "\n",
    "# variable size and seed\n",
    "MIX_steps = 1500 # 12000\n",
    "MIX_batch_size = 200\n",
    "MIX_weight_decay = [0.08, 0.06, 0.01, 0.005, 0.005] #[0.08, 0.06, 0.05, 0.035, 0.02] #dia #[0.06, 0.059, 0.058, 0.057, 0.055] #N0\n",
    "MIX_epochs = [int((MIX_steps*MIX_batch_size)/(x*800)) for x in sizes]\n",
    "MIX_results = []\n",
    "\n",
    "for k in range(len(sizes)):\n",
    "    MIX_sizeresults = []\n",
    "    for i in seeds:\n",
    "        MIX_seedresults, _ = encoderperf(diadata, kfold=False, checkpoint=MIX_checkpoint, epochs=MIX_epochs[k], lr=0.0001, seed=i, batch_size=MIX_batch_size, trainsize=sizes[k], weight_decay=MIX_weight_decay[k], en_weight_decay=0.01, encoder_type=\"mix\")\n",
    "        MIX_sizeresults.append(MIX_seedresults)\n",
    "    MIX_results.append(MIX_sizeresults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append to results\n",
    "results.append(MIX_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aucplot(results, sizes, title=\"Mix Encoder\", save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train combined encoder\n",
    "checkpoint1 = \"add your VIME checkpoint here\"\n",
    "checkpoint2 = \"add your MIX checkpoint here\"\n",
    "\n",
    "\n",
    "# variable size and seed\n",
    "COM_steps = 4000 #3000 # 12000\n",
    "COM_batch_size = 200\n",
    "COM_weight_decay = [0.005, 0.005, 0.005, 0.005, 0] # dia #[0.05, 0.049, 0.048, 0.047, 0.045] # N0\n",
    "COM_encoder_decay = [0, 0, 0, 0, 0] # dia #[0.05, 0.045, 0.035, 0.025, 0.015] # N0\n",
    "COM_epochs = [int((COM_steps*COM_batch_size)/(x*800)) for x in sizes]\n",
    "COM_results = []\n",
    "\n",
    "for k in range(len(sizes)):\n",
    "    COM_sizeresults = []\n",
    "    for i in seeds:\n",
    "        COM_seedresults, _ = combinedencodertrain(diadata, checkpoint=checkpoint1, checkpoint2=checkpoint2, batch_size=COM_batch_size, lr=0.0001, epochs=COM_epochs[k], trainsize=sizes[k], seed=i, weight_decay=COM_weight_decay[k], en_weight_decay=COM_encoder_decay[k])\n",
    "        COM_sizeresults.append(COM_seedresults)\n",
    "    COM_results.append(COM_sizeresults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append to results\n",
    "results.append(COM_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aucplot(results, sizes, title=\"Combined Encoder\", save=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
